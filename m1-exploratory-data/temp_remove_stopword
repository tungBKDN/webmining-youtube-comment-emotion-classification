import pandas as pd
from tqdm import tqdm
import re

# Constants
START_IDX = 6291  # replace with your actual start index
END_IDX = 6366  # replace with your actual end index

# Example stopword list (replace with your actual list)
with open('./data/vietnamese-stopwords.txt', encoding='utf-8') as f:
   stopwords = [line.strip() for line in f if line.strip()]
# Order stopwords backward
stopwords = sorted(stopwords, reverse=True)

# Example: Load your DataFrame (replace with your actual file path)
df = pd.read_csv('./data/labeled-data.csv')  # assumes a column 'comment'

def remove_stopwords(text, stopwords):
   # Prioritize longer stopwords first (already sorted in reverse order)
   result = text
   for sw in stopwords:
      # Use word boundaries to avoid partial matches
      pattern = r'\b' + re.escape(sw) + r'\b'
      result = re.sub(pattern, '', result, flags=re.IGNORECASE)
   # Remove extra spaces
   result = re.sub(r'\s+', ' ', result).strip()
   return result

# Apply stopword removal for rows in the specified range
for idx in tqdm(range(START_IDX, END_IDX), desc="Removing stopwords"):
   if idx < len(df):
      df.at[idx, 'comment_nonsw'] = remove_stopwords(df.at[idx, 'comment'], stopwords)

# Save the result (optional)
df.to_csv('comments_no_stopwords.csv', index=False)