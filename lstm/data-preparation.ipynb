{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cd76ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1.0    1452\n",
      "0.0    1261\n",
      "3.0    1030\n",
      "2.0    1010\n",
      "7.0     600\n",
      "4.0     529\n",
      "5.0     502\n",
      "6.0     501\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../data/labeled-data.csv')\n",
    "\n",
    "# Print the number of rows by label\n",
    "print(data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5252af71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum by label:\n",
      "Label 0: 1100\n",
      "Label 1: 1100\n",
      "Label 2: 1010\n",
      "Label 3: 1030\n",
      "Label 4: 529\n",
      "Label 5: 502\n",
      "Label 6: 501\n",
      "Label 7: 550\n"
     ]
    }
   ],
   "source": [
    "train_num = [900, 900, 810, 830, 379, 352, 351, 400]\n",
    "val_num   = [100, 100, 100, 100,  50,  50,  50,  50]\n",
    "test_num  = [100, 100, 100, 100, 100, 100, 100, 100]\n",
    "\n",
    "print(\"Sum by label:\")\n",
    "for i in range(8):\n",
    "    print(f\"Label {i}: {train_num[i] + val_num[i] + test_num[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae79846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each label, create train, validation, and test sets based on the counts above\n",
    "def split_data(df, train_counts, val_counts, test_counts):\n",
    "    train_dfs = []\n",
    "    val_dfs = []\n",
    "    test_dfs = []\n",
    "\n",
    "    for label in df['label'].unique():\n",
    "        label_df = df[df['label'] == label]\n",
    "        train_size = train_counts[int(label)]\n",
    "        val_size = val_counts[int(label)]\n",
    "        test_size = test_counts[int(label)]\n",
    "\n",
    "        train_df = label_df.sample(n=train_size, random_state=42)\n",
    "        remaining = label_df.drop(train_df.index)\n",
    "        val_df = remaining.sample(n=val_size, random_state=42)\n",
    "        test_df = remaining.drop(val_df.index).sample(n=test_size, random_state=42)\n",
    "\n",
    "        train_dfs.append(train_df)\n",
    "        val_dfs.append(val_df)\n",
    "        test_dfs.append(test_df)\n",
    "\n",
    "    return pd.concat(train_dfs), pd.concat(val_dfs), pd.concat(test_dfs)\n",
    "\n",
    "train_df, val_df, test_df = split_data(data, train_num, val_num, test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590e1e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in each label after oversampling:\n",
      "label\n",
      "2.0    900\n",
      "0.0    900\n",
      "6.0    900\n",
      "1.0    900\n",
      "4.0    900\n",
      "3.0    900\n",
      "7.0    900\n",
      "5.0    900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversampling the minority classes in the training set, targer: 900 samples per class\n",
    "def oversample_minority_classes(train_df, target_size):\n",
    "    oversampled_dfs = []\n",
    "    for label in train_df['label'].unique():\n",
    "        label_df = train_df[train_df['label'] == label]\n",
    "        if len(label_df) < target_size:\n",
    "            # Oversample the minority class\n",
    "            oversampled_label_df = label_df.sample(n=target_size, replace=True, random_state=42)\n",
    "        else:\n",
    "            oversampled_label_df = label_df\n",
    "        oversampled_dfs.append(oversampled_label_df)\n",
    "\n",
    "    return pd.concat(oversampled_dfs)\n",
    "\n",
    "train_df = oversample_minority_classes(train_df, 900)\n",
    "# Print the number of rows in each label after oversampling\n",
    "print(\"Number of rows in each label after oversampling:\")\n",
    "print(train_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c849151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in each label after validation oversampling:\n",
      "label\n",
      "2.0    100\n",
      "0.0    100\n",
      "6.0    100\n",
      "1.0    100\n",
      "4.0    100\n",
      "3.0    100\n",
      "7.0    100\n",
      "5.0    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_df = oversample_minority_classes(val_df, 100)\n",
    "# Print the number of rows in each label after validation oversampling\n",
    "print(\"Number of rows in each label after validation oversampling:\")\n",
    "print(val_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e93d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "train_df.to_csv('./processed-data/train.csv', index=False)\n",
    "val_df.to_csv('./processed-data/val.csv', index=False)\n",
    "test_df.to_csv('./processed-data/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
